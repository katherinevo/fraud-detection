<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta content="width=device-width, initial-scale=1.0" name="viewport">

  <title> K-Nearest Neighbors </title>
  <meta content="" name="description">
  <meta content="" name="keywords">

  <!-- Favicons -->
  <link href="assets/img/favicon.png" rel="icon">
  <link href="assets/img/apple-touch-icon.png" rel="apple-touch-icon">

  <!-- Google Fonts -->
  <link href="https://fonts.googleapis.com/css?family=Open+Sans:300,300i,400,400i,600,600i,700,700i|Nunito:300,300i,400,400i,600,600i,700,700i|Poppins:300,300i,400,400i,500,500i,600,600i,700,700i" rel="stylesheet">

  <!-- Vendor CSS Files -->
  <link href="assets/vendor/aos/aos.css" rel="stylesheet">
  <link href="assets/vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">
  <link href="assets/vendor/bootstrap-icons/bootstrap-icons.css" rel="stylesheet">
  <link href="assets/vendor/glightbox/css/glightbox.min.css" rel="stylesheet">
  <link href="assets/vendor/remixicon/remixicon.css" rel="stylesheet">
  <link href="assets/vendor/swiper/swiper-bundle.min.css" rel="stylesheet">

  <!-- Template Main CSS File -->
  <link href="assets/css/style.css" rel="stylesheet">

  <!-- =======================================================
  * Template Name: FlexStart - v1.9.0
  * Template URL: https://bootstrapmade.com/flexstart-bootstrap-startup-template/
  * Author: BootstrapMade.com
  * License: https://bootstrapmade.com/license/
  ======================================================== -->
</head>

<body>

  <!-- ======= Header ======= -->
  <header id="header" class="header fixed-top">
    <div class="container-fluid container-xl d-flex align-items-center justify-content-between">

      <a href="index.html" class="logo d-flex align-items-center">
        <img src="assets/img/parallelprocessing.png" alt="">
        <span></span>
      </a>

      <nav id="navbar" class="navbar">
        <ul>
          <li><a class="nav-link scrollto " href="index.html">Home</a></li>
        </ul>
        <i class="bi bi-list mobile-nav-toggle"></i>
      </nav><!-- .navbar -->

    </div>
  </header><!-- End Header -->

  <main id="main">

    <!-- ======= Breadcrumbs ======= -->
    <section class="breadcrumbs">
      <div class="container">
        
        <h2 style="text-align:center;">K-Nearest Neighbors (KNN)</h2>

      </div>
    </section><!-- End Breadcrumbs -->

    <!-- ======= Blog Single Section ======= -->
    <section id="blog" class="blog">
      <div class="container" data-aos="fade-up">

        <div class="row">

          <div>

            <article class="entry entry-single">

              <h2 class="entry-title">
                What is KNN?
              </h2>

        

              <div class="entry-content">
                <p>
                  K-NN is a supervised machine learning algorithm that predicts similarity between new data (x_test inputs) and available data (x_train, y_train inputs). The code import KNN from the SKLearn Library is as follows:

                </p>
                <blockquote>
                  <p>
                    from sklearn.neighbors import KNeighborsClassifier as KNN
                  </p>
                </blockquote>
                
                <div class="entry-img">
                <center><img src="http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1531424125/KNN_final_a1mrv9.png" alt="KNN Concept" class="img-fluid"></center>
              </div>
                
                <h3>
                  Why KNN?</h3>

                  <p>
                    K-NN can be used for regression and classification. In our case, we used K-NN to classify if a transaction was fraud or not (i.e. binary classification). 
                </p>
                <center><img src="https://static.javatpoint.com/tutorial/machine-learning/images/k-nearest-neighbor-algorithm-for-machine-learning2.png" alt="KNN Concept" class="img-fluid" style="vertical-align:middle;"></center>
                <h3>
                  How?</h3>
                <p>
                  To simplify it into 2-D space, (since we have >2 features, hence a very complex plane) let’s say that we are predicting what an input should be classified/categorized as by taking the Euclidean distance* of every data point in the space.

                  </p>
                <center><img src = "https://static.javatpoint.com/tutorial/machine-learning/images/k-nearest-neighbor-algorithm-for-machine-learning4.png" alt="KNN Concept" class="img-fluid" style="vertical-align:middle;"></center>
                <p><small>
                  *Keep in mind, there are many other distance metrics that can be used to find the K-Nearest Neighbor, but Euclidean distance was the simplest for us to implement.</small>
                </p>
                <p>
                  With the closest data points from your input, we would take the closest K-Number of Neighbors (specified by you). Then, take a majority vote** of which category of points is seen more, and the input will be classified as that category.
                </p>
                <center><img src = "https://static.javatpoint.com/tutorial/machine-learning/images/k-nearest-neighbor-algorithm-for-machine-learning5.png" alt="KNN Concept" class="img-fluid" style="vertical-align:middle;"></center>
                <p>
                  <small>** Good thing to note is that since it’s based on voting, you would want a tie-breaker in the case that there is an equal number of points for both categories.</small>
                </p>
                <p>
                  If you want to learn more about KNN, and what makes KNN's implementation simple, click the link here:
                </p>
                <a href = "https://www.javatpoint.com/k-nearest-neighbor-algorithm-for-machine-learning">K-Nearest Neighbors: Algorithm for ML</a>
                <br>
                <br>
                <h2 class="entry-title">Our KNN Experience</h2>
                <h5>Data and Analysis</h5>
                <p>
                  Through multiple trials, we found that the K-Nearest Neighbors algorithm was a highly accurate machine learning model that landed a <strong>99.95% accuracy score</strong>, with a <strong>0.94 precision, recall, and f1-score</strong>.
                  Knowing this, you can see in our heat-map below that our model had 19,977 true positive predictions (top left), 7 true negative predictions (bottom right), and only 11 false negatives (bottom left) and 0
                  false positives (top right). Therefore, our model made only 11 mistakes; these mistakes would be the worst case scenario since it's better to have false alarms (false positive) rather than a fraud case
                  being swept under the rug (false negative).
                </p>
                <center><img src="assets/img/knn_heatmap.png" class="img-fluid" alt=""></center>

                
                <h3>Hyper-parameter Tuning</h3>
                <p>
                  <strong>N_Neighbors</strong>
                  <br>
                  <br>
                  N_neighbors is the specified number of data points closest to the new input that will be used to classify said input. This parameter
                  is of type 'int' and is defaulted to 5 neighbors.
                  <br>
                  <br>
                  <strong>Weights</strong>
                  <br>
                  <br>
                  Weights is the function that specifies how much each feature influences/affects our model's prediction based on distance. This parameter
                  is of type 'string' and is defaulted to 'uniform.'
                  <br>
                  <br>
                  <strong>Algorithm</strong>
                  <br>
                  <br>
                  The algorithm used to compute the nearest neighbors from the new input based on the specified distance metric. All of the algorithms
                  consist of:
                </p>
                <ul>
                  <li>
                    <code>
                    <span class="pre">ball_tree</span>
                    </code>
                  </li>
                  <li>
                    <code>
                    <span class="pre">kd_tree</span>
                    </code>
                  </li>
                  <li>
                    <code>
                    <span class="pre">brute</span>
                    </code>
                  </li>
                  <li>
                    <code>
                    <span class="pre">auto</span>
                    </code>
                  </li>
                </ul>
                <p>
                  The algorithm hyper-parameter is defaulted to 'auto,' meaning the program will automatically choose the algorithm 
                  appropriate for the values passed by the 
                <code>
                    <span class="pre">fit</span>
                </code>
                  method.
                </p>
                <small>
                  For further reading of the hyper-parameters set in the KNN algorithm, read here: 
                  <a href="https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html" target="_blank">KNN Documentation</a>
                </small>

            </article><!-- End blog entry -->


          </div><!-- End blog sidebar -->

        </div>

      </div>
    </section><!-- End Blog Single Section -->

  </main><!-- End #main -->
<!-- ======= Footer ======= -->
 <footer id="footer" class="footer">

    <div class="footer-top">
      <div class="container">
        <div class="row gy-4">
          <div class="col-lg-5 col-md-12 footer-info">
            <a href="index.html" class="logo d-flex align-items-center">
              <img src="assets/img/logo.png" alt="">
              <span>Parallel Processing</span>
            </a>
            <div class="social-links mt-3">
              <a href="https://www.instagram.com/aicamp1/" class="instagram"><i class="bi bi-instagram"></i></a>
              <a href="https://www.linkedin.com/company/ai-camp/" class="linkedin"><i class="bi bi-linkedin"></i></a>
            </div>
          </div>

          <div class="col-lg-2 col-6 footer-links">
            <h4>Useful Links</h4>
            <ul>
              <li><i class="bi bi-chevron-right"></i> <a href="index.html">Introduction</a></li>
              <li><i class="bi bi-chevron-right"></i> <a href="index.html">Exploratory Data Analysis</a></li>
              <li><i class="bi bi-chevron-right"></i> <a href="index.html">Machine Learning</a></li>
              <li><i class="bi bi-chevron-right"></i> <a href="index.html">Conclusion</a></li>
              <li><i class="bi bi-chevron-right"></i> <a href="index.html">About Us</a></li>
            </ul>
          </div>
        </div>
      </div>
    </div>

    <div class="container">
      <div class="copyright">
        &copy; Copyright <strong><span>Parallel Processing</span></strong>. All Rights Reserved
      </div>
      <div class="credits">
        <!-- All the links in the footer should remain intact. -->
        <!-- You can delete the links only if you purchased the pro version. -->
        <!-- Licensing information: https://bootstrapmade.com/license/ -->
        <!-- Purchase the pro version with working PHP/AJAX contact form: https://bootstrapmade.com/flexstart-bootstrap-startup-template/ -->
      </div>
    </div>
  </footer><!-- End Footer -->

  <a href="#" class="back-to-top d-flex align-items-center justify-content-center"><i class="bi bi-arrow-up-short"></i></a>

  <!-- Vendor JS Files -->
  <script src="assets/vendor/purecounter/purecounter.js"></script>
  <script src="assets/vendor/aos/aos.js"></script>
  <script src="assets/vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
  <script src="assets/vendor/glightbox/js/glightbox.min.js"></script>
  <script src="assets/vendor/isotope-layout/isotope.pkgd.min.js"></script>
  <script src="assets/vendor/swiper/swiper-bundle.min.js"></script>
  <script src="assets/vendor/php-email-form/validate.js"></script>

  <!-- Template Main JS File -->
  <script src="assets/js/main.js"></script>

</body>

</html>